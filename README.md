# Sampling via Föllmer Flow

<!-- ![evolution](assets/evolution.png) -->
<center><img src="./assets/evolution.png" alt="evolution" width="450" height="300"></center>

## Brief

We introduce a novel **unit-time ODE flow** called the Föllmer flow, which efficiently transforms a Gaussian measure into a desired target measure at time 1. We apply Euler's method, where the velocity field is calculated either analytically or through **Monte Carlo** approximation using Gaussian samples.

Through numerical experiments on mixture distributions in 1D, 2D, and  high-dimensional spaces, we demonstrate that the samples generated by our proposed flow exhibit higher quality compared to those obtained by several existing methods.

We also propose leveraging the Föllmer flow as a warmstart strategy for existing Markov Chain Monte Carlo (MCMC) methods, aiming to mitigate mode collapses and enhance their performance.

We can also leverage deep neural networks to fit  the trajectory of sample evaluations. This allows us to obtain a generator for **one-step** sampling as a result.

## Prerequisite

```bash
pip install -r requirements
``` 

## Assets

Our assets (samples(.npz), checkpoints(.pth), tables(.csv) and figures(.pdf,.png)) have been uploaed to [Google drive](https://drive.google.com/drive/folders/1GKR-L5Ak6dhPad8OP72oRP1EGJObIeZW?usp=sharing)

## Reproduce

```bash
.
├── Makefile
├── README.md
├── assets
├── distribution.py # abstract base class for general distribution, we implemented n-D Gaussian mixtures here
├── example.py # correspond to examples in table 3 of our paper
├── fflow.py # prototype of Föllmer flow
├── main.py # entrance for different routines (generate samples, train/eval networks)
├── mcmc.py # MCMC samplers prototype, modified from https://github.com/Tom271/LangevinMC/blob/master/langevin_traj.py
├── metric.py # compute MMD and W2 distance
├── misc.py # miscellaneous helper utilities
├── network.py # ResNet prototype
├── reproduce.py # entrance file to reproduce tables and figures from paper
├── requirements.txt
└── run.sh # bash scripts, calling main.py
```

config your python environment in [run.sh](run.sh)

Generate samples:
```bash
./run.sh 1d # sampling from example 1 - 3, with Föllmer flow & MCMC
./run.sh 2d # sampling from example 4 - 10, with Föllmer flow & MCMC
./run.sh 2dmc # sampling from example 4 - 10, with MC Föllmer flow
./run.sh precondition # sampling from example 5, with different preconditioners
./run.sh hybrid # sampling from example 7, with predictor-corrector scheme
./run.sh nd # sampling from example 11-19, dimension ranges from 1 to 10
./run.sh train # train neural sampler for example 4-10
./run.sh eval # evaluate(sampling) neural sampler for example 4-10
```

Reproduce tables and figures:
```bash
python reproduce.py table1 # compute metrics for example 1 - 3
python reproduce.py table2 # compute metrics for example 4 - 10
python reproduce.py fig1 # evolution
python reproduce.py fig2 # plot for example 1 - 3
python reproduce.py fig3 # plot for example 4 - 10
python reproduce.py fig4 # plot influences of preconditioner
python reproduce.py fig5 # compare original and hybrid MCMC methods
python reproduce.py fig6 # plot n-D moments
```

## Secondary Development

If you wish to try Föllmer flow for specific distribution, please look into the abstract base class `BaseDistribution` in [distribution.py](distribution.py) and implement at least `ln_scaled_ratio` to run the MC Föllmer flow, or even better the `velocity_closed` method if there is a closed-form representation to run the closed-form Föllmer flow. Then just call `fflow_sampler` and feed the `velocity_fn` to it.

## References
> https://github.com/Tom271/LangevinMC/blob/master/langevin_traj.py